# src/data/video_data.py
from typing import List, Dict, Any
from pathlib import Path

import pandas as pd
import streamlit as st

import config.config as cfg

# êµ¬ì¢… ID -> Statcast pitch_type ì½”ë“œ ë§¤í•‘
PITCH_SHORT_CODE = {
    0: "CU",
    1: "FC",
    2: "FF",
    3: "FS",
    4: "SI",
    5: "SL",
    6: "ST",
}


@st.cache_data
def load_video_analysis(_file_mtime: float = 0) -> pd.DataFrame | None:
    """
    data_extraction_mlbì—ì„œ ìƒì„±í•œ í†µí•© ë¶„ì„ CSV ë¡œë“œ
    (Statcast + ì˜ìƒ ë¶„ì„ + íŒ”ê°ë„ + ì˜ìƒ ê²½ë¡œ)
    
    Args:
        _file_mtime: íŒŒì¼ ìˆ˜ì • ì‹œê°„ (ìºì‹œ í‚¤ë¡œ ì‚¬ìš©, íŒŒì¼ ë³€ê²½ ì‹œ ìë™ ê°±ì‹ )
    """
    csv_path: Path = cfg.FINAL_MERGED_CSV

    if not csv_path.exists():
        st.warning(f"ì˜ìƒ ë¶„ì„ í†µí•© CSVë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_path}")
        return None
    
    df = pd.read_csv(csv_path)

    # ë‚ ì§œ ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ datetimeìœ¼ë¡œ (ë¨¼ì € ë³€í™˜í•˜ì—¬ í•„í„°ë§ì— ì‚¬ìš©)
    if "game_date" in df.columns:
        df["game_date"] = pd.to_datetime(df["game_date"], errors="coerce")
        df["year"] = df["game_date"].dt.year
    
    # 2025ë…„ ì˜ìƒì´ ìˆëŠ” ë°ì´í„°ë§Œ í•„í„°ë§
    # output_video_pathê°€ ìˆê³ , ë‚ ì§œê°€ 2025ë…„ì¸ ë°ì´í„°ë§Œ ì‚¬ìš©
    if "output_video_path" in df.columns:
        # output_video_pathê°€ ìˆëŠ” í–‰ë§Œ í•„í„°ë§
        has_video = df["output_video_path"].notna()
        
        # 2025ë…„ ë°ì´í„°ë§Œ í•„í„°ë§ (ì˜ìƒ ê²½ë¡œì—ì„œ ë‚ ì§œ ì¶”ì¶œ ë˜ëŠ” game_date ì‚¬ìš©)
        if "year" in df.columns:
            is_2025 = df["year"] == 2025
        else:
            # output_video_pathì—ì„œ 2025 ì¶”ì¶œ
            import re
            is_2025 = df["output_video_path"].apply(
                lambda x: bool(re.search(r"2025", str(x))) if pd.notna(x) else False
            )
        
        # 2025ë…„ ì˜ìƒì´ ìˆëŠ” ë°ì´í„°ë§Œ í•„í„°ë§
        df = df[has_video & is_2025].copy()
        
        if len(df) == 0:
            st.warning("2025ë…„ ì˜ìƒ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # ì¤‘ë³µ ì œê±° (game_pk, at_bat_number, pitch_number ê¸°ì¤€)
        df = df.drop_duplicates(subset=["game_pk", "at_bat_number", "pitch_number"], keep="first")
        
        st.info(f"ğŸ“¹ 2025ë…„ ì˜ìƒ ë°ì´í„° {len(df)}ê°œë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")

    # ìì£¼ ì“°ëŠ” ì»¬ëŸ¼ íƒ€ì… ì •ë¦¬
    int_cols = [
        "balls",
        "strikes",
        "outs_when_up",
        "on_1b",
        "on_2b",
        "on_3b",
        "inning",
    ]
    for col in int_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce")


    # ë‚ ì§œ/êµ¬ì¢… ì½”ë“œ íŒŒìƒ (data_extraction_mlb/app.py ì™€ ë™ì¼ ë¡œì§)
    import re

    if "output_video_path" in df.columns:
        # ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
        def normalize_video_path(path_str):
            if pd.isna(path_str) or not path_str:
                return path_str
            path_str = str(path_str).strip()
            
            # íŒŒì¼ëª… ì¶”ì¶œ (ê²½ë¡œ êµ¬ë¶„ì ì²˜ë¦¬)
            if "/" in path_str:
                filename = path_str.split("/")[-1]
            elif "\\" in path_str:
                filename = path_str.split("\\")[-1]
            else:
                filename = path_str
            
            # íŒŒì¼ëª…ì´ ë¹„ì–´ìˆìœ¼ë©´ ì›ë˜ ê²½ë¡œ ë°˜í™˜
            if not filename:
                return path_str
            
            # 1ìˆœìœ„: analyzed_videos í´ë” í™•ì¸ (ë¶„ì„ëœ ì˜ìƒ)
            absolute_path = cfg.ANALYZED_VIDEOS_DIR / filename
            if absolute_path.exists() and absolute_path.is_file():
                return str(absolute_path.resolve())
            
            # 2ìˆœìœ„: 2025_data/videos í´ë” í™•ì¸
            videos_2025_dir = cfg.DE_RESULTS_DIR / "2025_data" / "videos"
            if videos_2025_dir.exists():
                video_2025_path = videos_2025_dir / filename
                if video_2025_path.exists() and video_2025_path.is_file():
                    return str(video_2025_path.resolve())
            
            # 3ìˆœìœ„: ì›ë³¸ ì˜ìƒ í´ë” í™•ì¸ (ohtani_videos/2025/)
            # íŒŒì¼ëª…ì—ì„œ _analyzed ì œê±°í•˜ì—¬ ì›ë³¸ íŒŒì¼ëª… ì°¾ê¸°
            original_filename = filename.replace("_analyzed.mp4", ".mp4")
            
            # ë‚ ì§œì—ì„œ ì—°ë„ ì¶”ì¶œ (ì˜ˆ: 2025-10-28 -> 2025)
            import re
            date_match = re.search(r"(\d{4})-\d{2}-\d{2}", original_filename)
            if date_match:
                year = date_match.group(1)
                # ì—°ë„ í´ë” ë‚´ì—ì„œ ê²€ìƒ‰ (ì˜ˆ: ohtani_videos/2025/)
                if cfg.ORIGINAL_VIDEOS_DIR.exists():
                    original_video_path = cfg.ORIGINAL_VIDEOS_DIR / year / original_filename
                    if original_video_path.exists() and original_video_path.is_file():
                        return str(original_video_path.resolve())
                    
                    # ì—°ë„ í´ë” ì—†ì´ ì§ì ‘ í™•ì¸
                    original_video_path_direct = cfg.ORIGINAL_VIDEOS_DIR / original_filename
                    if original_video_path_direct.exists() and original_video_path_direct.is_file():
                        return str(original_video_path_direct.resolve())
            
            # 4ìˆœìœ„: ëª¨ë“  í´ë”ì—ì„œ ì¬ê·€ì ìœ¼ë¡œ ê²€ìƒ‰ (ë§ˆì§€ë§‰ ìˆ˜ë‹¨)
            search_dirs = []
            if cfg.ORIGINAL_VIDEOS_DIR.exists():
                search_dirs.append(cfg.ORIGINAL_VIDEOS_DIR)
            if cfg.ANALYZED_VIDEOS_DIR.exists():
                search_dirs.append(cfg.ANALYZED_VIDEOS_DIR)
            if videos_2025_dir.exists():
                search_dirs.append(videos_2025_dir)
            
            for search_dir in search_dirs:
                # ì¬ê·€ì ìœ¼ë¡œ ì›ë³¸ íŒŒì¼ëª… ê²€ìƒ‰
                found_files = list(search_dir.rglob(original_filename))
                if found_files:
                    return str(found_files[0].resolve())
                # _analyzed ë²„ì „ë„ ê²€ìƒ‰
                found_files = list(search_dir.rglob(filename))
                if found_files:
                    return str(found_files[0].resolve())
            
            # íŒŒì¼ì„ ì°¾ì§€ ëª»í•œ ê²½ìš°ì—ë„ ì˜¬ë°”ë¥¸ ê²½ë¡œ êµ¬ì¡° ë°˜í™˜ (ë‚˜ì¤‘ì— ê²½ê³  í‘œì‹œ)
            # ì›ë³¸ ì˜ìƒ ê²½ë¡œë¥¼ ìš°ì„  ë°˜í™˜ (ê°€ì¥ ê°€ëŠ¥ì„± ë†’ìŒ)
            if date_match:
                year = date_match.group(1)
                fallback_path = cfg.ORIGINAL_VIDEOS_DIR / year / original_filename
                return str(fallback_path.resolve())
            
            return str(absolute_path.resolve())
        
        df["output_video_path"] = df["output_video_path"].apply(normalize_video_path)
        
        df["pitch_type_extracted"] = df["output_video_path"].apply(
            lambda x: re.search(r"_(FF|ST|CU|SL|FS|FC|SI|CH|KN)_", str(x)).group(1)
            if x and re.search(r"_(FF|ST|CU|SL|FS|FC|SI|CH|KN)_", str(x))
            else None
        )
        df["date_extracted"] = df["output_video_path"].apply(
            lambda x: re.search(r"(\d{4}-\d{2}-\d{2})", str(x)).group(1)
            if x and re.search(r"(\d{4}-\d{2}-\d{2})", str(x))
            else None
        )
        df["date"] = pd.to_datetime(df["date_extracted"], errors="coerce")
    else:
        df["pitch_type_extracted"] = None
        df["date"] = pd.NaT

    return df


def find_similar_pitches(
    video_df: pd.DataFrame,
    input_data: Dict[str, Any],
    pitch_id: int,
    max_results: int = 3,
) -> List[Dict[str, Any]]:
    """
    í˜„ì¬ ìƒí™©(input_data) + ì¶”ì²œ êµ¬ì¢…(pitch_id)ì— ë¹„ìŠ·í•œ ê³¼ê±° íˆ¬êµ¬ë“¤ì„ ì°¾ì•„
    ì˜ìƒ/íŒ”ê°ë„/íƒì§€ìœ¨ ì •ë³´ë¥¼ ë°˜í™˜.
    """
    if video_df is None or len(video_df) == 0:
        return []

    if "pitch_type" not in video_df.columns:
        return []

    pitch_code = PITCH_SHORT_CODE.get(pitch_id)
    if pitch_code is None:
        return []

    df = video_df.copy()

    # 1ì°¨ í•„í„°: êµ¬ì¢… + ì¹´ìš´íŠ¸ + ì•„ì›ƒ + ì£¼ì + ì´ë‹
    cond = (df["pitch_type"] == pitch_code)

    # input_dataì— ìˆëŠ” ê²½ìš°ì—ë§Œ í•„í„° ì ìš©
    def _safe_eq(col: str, key: str):
        nonlocal cond
        if col in df.columns and key in input_data:
            cond = cond & (df[col] == input_data[key])

    _safe_eq("balls", "balls")
    _safe_eq("strikes", "strikes")
    _safe_eq("outs_when_up", "outs_when_up")
    _safe_eq("on_1b", "on_1b")
    _safe_eq("on_2b", "on_2b")
    _safe_eq("on_3b", "on_3b")
    _safe_eq("inning", "inning")

    filtered = df[cond]

    # ê²°ê³¼ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ì¡°ê±´ ì™„í™”: ì¹´ìš´íŠ¸ë§Œ ë§ì¶”ê³  ë‚˜ë¨¸ì§€ëŠ” í’€ì–´ì¤Œ
    if len(filtered) < max_results:
        cond_relaxed = df["pitch_type"] == pitch_code
        if "balls" in df.columns and "balls" in input_data:
            cond_relaxed &= df["balls"] == input_data["balls"]
        if "strikes" in df.columns and "strikes" in input_data:
            cond_relaxed &= df["strikes"] == input_data["strikes"]
        filtered = df[cond_relaxed]

    if len(filtered) == 0:
        return []

    # íƒì§€ìœ¨ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬ (ì—†ìœ¼ë©´ ì›ë˜ ìˆœì„œ ìœ ì§€)
    if "detection_rate" in filtered.columns:
        filtered = filtered.sort_values("detection_rate", ascending=False)

    filtered = filtered.head(max_results)

    results: List[Dict[str, Any]] = []
    for _, row in filtered.iterrows():
        results.append(
            {
                "game_date": row.get("game_date"),
                "balls": row.get("balls"),
                "strikes": row.get("strikes"),
                "outs": row.get("outs_when_up"),
                "on_1b": row.get("on_1b"),
                "on_2b": row.get("on_2b"),
                "on_3b": row.get("on_3b"),
                "pitch_type": row.get("pitch_type"),
                "output_video_path": row.get("output_video_path"),
                "calculated_release_angle": row.get("calculated_release_angle"),
                "detection_rate": row.get("detection_rate"),
                "description": row.get("description") or row.get("des"),
            }
        )

    return results